{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a00017a8-415d-436a-98dd-a1be66ed834d",
   "metadata": {},
   "source": [
    "[DIY Disease Tracking Dashboard Kit](https://github.com/fsmeraldi/diy-covid19dash) (C) Fabrizio Smeraldi, 2020,2024 ([f.smeraldi@qmul.ac.uk](mailto:f.smeraldi@qmul.ac.uk) - [web](http://www.eecs.qmul.ac.uk/~fabri/)). This notebook is released under the [GNU GPLv3.0 or later](https://www.gnu.org/licenses/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8315a0e-49ae-43a2-b498-f89351197ab7",
   "metadata": {},
   "source": [
    "# DIY Disease Tracking Dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70865dd1-e5df-4789-8a52-96dc64a7d194",
   "metadata": {},
   "source": [
    "This is a simple dashboard based on UKHSA data, displaying the daily COVID-19 admissions across different NHS regions.\n",
    "\n",
    "The development of this dashboard is Chengkai's independent work, reusing code provided in the guidelines by Fabrizio. \n",
    "\n",
    "Special thanks to Fabrizio and the TAs for providing the foundational code and guidance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9ee43006-9021-4a72-90f3-d1f652bfa379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tutorial code reused for class APIwrapper\n",
    "import requests\n",
    "import time\n",
    "\n",
    "class APIwrapper:\n",
    "    # class variables shared among all instances\n",
    "    _access_point=\"https://api.ukhsa-dashboard.data.gov.uk\"\n",
    "    _last_access=0.0 # time of last api access\n",
    "    \n",
    "    def __init__(self, theme, sub_theme, topic, geography_type, geography, metric):\n",
    "        \"\"\" Init the APIwrapper object, constructing the endpoint from the structure\n",
    "        parameters \"\"\"\n",
    "        # build the path with all the required structure parameters. You do not need to edit this line,\n",
    "        # parameters will be replaced by the actual values when you instantiate an object of the class!\n",
    "        url_path=(f\"/themes/{theme}/sub_themes/{sub_theme}/topics/{topic}/geography_types/\" +\n",
    "                  f\"{geography_type}/geographies/{geography}/metrics/{metric}\")\n",
    "        # our starting API endpoint\n",
    "        self._start_url=APIwrapper._access_point+url_path\n",
    "        self._filters=None\n",
    "        self._page_size=-1\n",
    "        # will contain the number of items\n",
    "        self.count=None\n",
    "\n",
    "    def get_page(self, filters={}, page_size=5):\n",
    "        \"\"\" Access the API and download the next page of data. Sets the count\n",
    "        attribute to the total number of items available for this query. Changing\n",
    "        filters or page_size will cause get_page to restart from page 1. Rate\n",
    "        limited to three request per second. The page_size parameter sets the number\n",
    "        of data points in one response page (maximum 365); use the default value \n",
    "        for debugging your structure and filters. \"\"\"\n",
    "        # Check page size is within range\n",
    "        if page_size>365:\n",
    "            raise ValueError(\"Max supported page size is 365\")\n",
    "        # restart from first page if page or filters have changed\n",
    "        if filters!=self._filters or page_size!=self._page_size:\n",
    "            self._filters=filters\n",
    "            self._page_size=page_size\n",
    "            self._next_url=self._start_url\n",
    "        # signal the end of data condition\n",
    "        if self._next_url==None: \n",
    "            return [] # we already fetched the last page\n",
    "        # simple rate limiting to avoid bans\n",
    "        curr_time=time.time() # Unix time: number of seconds since the Epoch\n",
    "        deltat=curr_time-APIwrapper._last_access\n",
    "        if deltat<0.33: # max 3 requests/second\n",
    "            time.sleep(0.33-deltat)\n",
    "        APIwrapper._last_access=curr_time\n",
    "        # build parameter dictionary by removing all the None\n",
    "        # values from filters and adding page_size\n",
    "        parameters={x: y for x, y in filters.items() if y!=None}\n",
    "        parameters['page_size']=page_size\n",
    "        # the page parameter is already included in _next_url.\n",
    "        # This is the API access. Response is a dictionary with various keys.\n",
    "        # the .json() method decodes the response into Python object (dictionaries,\n",
    "        # lists; 'null' values are translated as None).\n",
    "        response = requests.get(self._next_url, params=parameters).json()\n",
    "        # update url so we'll fetch the next page\n",
    "        self._next_url=response['next']\n",
    "        self.count=response['count']\n",
    "        # data are in the nested 'results' list\n",
    "        return response['results'] \n",
    "\n",
    "    def get_all_pages(self, filters={}, page_size=365):\n",
    "        \"\"\" Access the API and download all available data pages of data. Sets the count\n",
    "        attribute to the total number of items available for this query. API access rate\n",
    "        limited to three request per second. The page_size parameter sets the number\n",
    "        of data points in one response page (maximum 365), and controls the trade-off\n",
    "        between time to load a page and number of pages; the default should work well \n",
    "        in most cases. The number of items returned should in any case be equal to \n",
    "        the count attribute. \"\"\"\n",
    "        data=[] # build up all data here\n",
    "        while True:\n",
    "            # use get_page to do the job, including the pacing\n",
    "            next_page=self.get_page(filters, page_size)\n",
    "            if next_page==[]:\n",
    "                break # we are done\n",
    "            data.extend(next_page)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cb492196-96c7-437c-bb89-577658a1fd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The aim of the code below is to look at addmission by day for different regions (geography) across NHS Region\n",
    "structure={\"theme\": \"infectious_disease\", \n",
    "           \"sub_theme\": \"respiratory\",\n",
    "           \"topic\": \"COVID-19\",\n",
    "           \"geography_type\": \"NHS Region\", \n",
    "           \"metric\": \"COVID-19_healthcare_admissionByDay\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5f8b34ec-fe1e-4de2-93b8-409032de80f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "structure[\"geography\"]=\"London\"\n",
    "api=APIwrapper(**structure)\n",
    "Ldnadmissions=api.get_all_pages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a5528347-7b1f-4977-b6cb-a9ef612b376e",
   "metadata": {},
   "outputs": [],
   "source": [
    "structure[\"geography\"]=\"East of England\"\n",
    "api=APIwrapper(**structure)\n",
    "EEadmissions=api.get_all_pages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9224ee61-d7cd-49b9-8842-59b7748e3552",
   "metadata": {},
   "outputs": [],
   "source": [
    "structure[\"geography\"]=\"Midlands\"\n",
    "api=APIwrapper(**structure)\n",
    "MLadmissions=api.get_all_pages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b6d06aa1-1795-4252-8608-e2615df017de",
   "metadata": {},
   "outputs": [],
   "source": [
    "structure[\"geography\"]=\"North East and Yorkshire\"\n",
    "api=APIwrapper(**structure)\n",
    "NEadmissions=api.get_all_pages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "eb06dcee-1474-4804-b4a3-40f08926d438",
   "metadata": {},
   "outputs": [],
   "source": [
    "structure[\"geography\"]=\"North West\"\n",
    "api=APIwrapper(**structure)\n",
    "NWadmissions=api.get_all_pages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fdf63e6e-4071-462f-bfdb-121c50c1ce33",
   "metadata": {},
   "outputs": [],
   "source": [
    "structure[\"geography\"]=\"South East\"\n",
    "api=APIwrapper(**structure)\n",
    "SEadmissions=api.get_all_pages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7f629b18-0bca-4b40-a8f3-32bedd229627",
   "metadata": {},
   "outputs": [],
   "source": [
    "structure[\"geography\"]=\"South West\"\n",
    "api=APIwrapper(**structure)\n",
    "SWadmissions=api.get_all_pages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6914c0d8-ac1a-4f68-a451-80554388dfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data into json files\n",
    "import json\n",
    "with open(\"East of England.json\", \"wt\") as OUTF:\n",
    "    json.dump(EEadmissions, OUTF)\n",
    "\n",
    "with open(\"London.json\", \"wt\") as OUTF:\n",
    "    json.dump(Ldnadmissions, OUTF)\n",
    "\n",
    "with open(\"Midlands.json\", \"wt\") as OUTF:\n",
    "    json.dump(MLadmissions, OUTF)\n",
    "\n",
    "with open(\"North East and Yorkshire.json\", \"wt\") as OUTF:\n",
    "    json.dump(NEadmissions, OUTF)\n",
    "\n",
    "with open(\"North West.json\", \"wt\") as OUTF:\n",
    "    json.dump(NWadmissions, OUTF)\n",
    "\n",
    "with open(\"South East.json\", \"wt\") as OUTF:\n",
    "    json.dump(SEadmissions, OUTF)\n",
    "    \n",
    "with open(\"South West.json\", \"wt\") as OUTF:\n",
    "    json.dump(SWadmissions, OUTF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fc03cb27-79d8-49a8-b144-7ce8bd02df1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import ipywidgets as wdg\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.dpi'] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7464d3b4-4b1a-4e21-8ebd-6feaaca7630e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"East of England.json\", \"rt\") as INFILE:\n",
    "    EEadmissions=json.load(INFILE)\n",
    "with open(\"London.json\", \"rt\") as INFILE:\n",
    "    Ldnadmissions=json.load(INFILE)\n",
    "with open(\"Midlands.json\", \"rt\") as INFILE:\n",
    "    MLadmissions=json.load(INFILE)\n",
    "with open(\"North East and Yorkshire.json\", \"rt\") as INFILE:\n",
    "    NEnadmissions=json.load(INFILE)\n",
    "with open(\"North West.json\", \"rt\") as INFILE:\n",
    "    NWadmissions=json.load(INFILE)\n",
    "with open(\"South West.json\", \"rt\") as INFILE:\n",
    "    SWnadmissions=json.load(INFILE)\n",
    "with open(\"South East.json\", \"rt\") as INFILE:\n",
    "    SEadmissions=json.load(INFILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "52c97ef5-50dd-499b-b237-c8f68499c103",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "for dataset in [EEadmissions, Ldnadmissions, MLadmissions, NEadmissions, NWadmissions, SEadmissions, SWadmissions]:\n",
    "    for entry in dataset:\n",
    "        date = entry['date']\n",
    "        geography = entry['geography']\n",
    "        metric = entry['metric']\n",
    "        value = entry['metric_value']\n",
    "        \n",
    "        # Ensure the date exists in the dictionary\n",
    "        if date not in data:\n",
    "            data[date] = {}\n",
    "        \n",
    "        # Include geography in the key structure\n",
    "        if geography not in data[date]:\n",
    "            data[date][geography] = {}\n",
    "        \n",
    "        # Store the metric value\n",
    "        data[date][geography][metric] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "205a4279-da5f-4efd-b1d3-b385deab061e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates=list(data.keys())\n",
    "dates.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e7de971b-9dbc-4030-b65b-4e1fdd4503df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tutorial code reused for converting a date seting into a pandas datetime object\n",
    "def parse_date(datestring):\n",
    "    \"\"\" Convert a date string into a pandas datetime object \"\"\"\n",
    "    return pd.to_datetime(datestring, format=\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "41e32f98-193b-4114-89b6-34ac903e60b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "startdate = parse_date(dates[0])\n",
    "enddate = parse_date(dates[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7234a54b-7b34-4ed6-ae20-afda366705c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "index=pd.date_range(startdate, enddate, freq='D')\n",
    "timeseriesdf=pd.DataFrame(index=index, columns=['East England','London','Midlands','North East','North West','South East','South West'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5831914e-9d07-4b4f-b3fe-18d5a66aa27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "geography ={'East England': 'East of England',\n",
    "          'London': 'London',\n",
    "          'Midlands': 'Midlands',\n",
    "          'North East': 'North East and Yorkshire',\n",
    "          'North West': 'North West',\n",
    "          'South East': 'South East',\n",
    "          'South West': 'South West'}\n",
    "\n",
    "for date, regions in data.items():\n",
    "    pd_date=parse_date(date) # convert to Pandas format\n",
    "    for column in geography.keys():\n",
    "        geo_name=geography[column]\n",
    "        # do not assume all values are there for every date - if a value is not available, insert a 0.0\n",
    "        value = regions.get(geo_name, {}).get('COVID-19_healthcare_admissionByDay', 0.0)\n",
    "        # this is the way you access a specific location in the dataframe - use .loc\n",
    "        # and put index,column in a single set of [ ]\n",
    "        timeseriesdf.loc[date, column]=value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092ced8f-0245-4d82-9c36-6a5975396224",
   "metadata": {},
   "source": [
    "## Download current data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af54529a-9c1d-4676-b79b-230ef2e889c7",
   "metadata": {},
   "source": [
    "Clicking the button below will allow you to download the latest available COVID-19 admission data directly from UKHSA. This ensures you always have access to the most up-to-date information for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "28126131-d7bc-4ec3-ba80-7d6bbc13dc3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b7f691515a04dc09e1dc89689dfb6b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Refresh data', icon='download', style=ButtonStyle(), tooltip='Click to download current Pu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def access_api(button):\n",
    "    structure = {\n",
    "        \"theme\": \"infectious_disease\",\n",
    "        \"sub_theme\": \"respiratory\",\n",
    "        \"topic\": \"COVID-19\",\n",
    "        \"geography_type\": \"NHS Region\",\n",
    "        \"metric\": \"COVID-19_healthcare_admissionByDay\",\n",
    "    }\n",
    "    \n",
    "    regions = {\n",
    "        \"East of England\": \"East of England.json\",\n",
    "        \"London\": \"London.json\",\n",
    "        \"Midlands\": \"Midlands.json\",\n",
    "        \"North East and Yorkshire\": \"North East and Yorkshire.json\",\n",
    "        \"North West\": \"North West.json\",\n",
    "        \"South East\": \"South East.json\",\n",
    "        \"South West\": \"South West.json\",\n",
    "    }\n",
    "# The try block is used to handle potential errors that could occur when run the code\n",
    "# This would ensure the program does not crash\n",
    "    try:\n",
    "        for region, filename in regions.items():\n",
    "            structure[\"geography\"] = region\n",
    "            api = APIwrapper(**structure)\n",
    "            data = api.get_all_pages()\n",
    "            with open(filename, \"wt\") as OUTF:\n",
    "                json.dump(data, OUTF)\n",
    "        apibutton.icon = \"check\"\n",
    "        apibutton.description = \"Done\"\n",
    "    except Exception as e:\n",
    "        print(f\"An error occured: {e}\")\n",
    "\n",
    "# Create and display button\n",
    "apibutton = wdg.Button(\n",
    "    description=\"Refresh data\",\n",
    "    disabled=False,\n",
    "    tooltip=\"Click to download current Public Health England data\",\n",
    "    icon=\"download\"\n",
    ")\n",
    "apibutton.on_click(access_api)\n",
    "display(apibutton)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1272893-bca0-49a6-bb53-c5edf7270f2d",
   "metadata": {},
   "source": [
    "## Graphs and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4ce20a-bedd-4ffc-a736-891a7dbb0663",
   "metadata": {},
   "source": [
    "The gragh below gives a visual representation of trends in COVID-19 admissions across NHS regions. It allows users to explore and analyse data by selecting one or more areas for comparison. This interactive feature shows how different regions have been affected over time, making it easier to identify patterns and regional differences in admissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b9bc19db-b1b9-49e2-b9b5-aee1d5f4a0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interactive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6a413f99-4f6c-4c94-9ea5-86552e55a2bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce0b8fa955f744d1bd86449b87b327a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(SelectMultiple(description='NHS Regions:', index=(1,), options=('East England', 'London'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "region_selector = wdg.SelectMultiple(\n",
    "    options=timeseriesdf.columns.unique(),\n",
    "    value=['London'],  # Default selected region london\n",
    "    description='NHS Regions:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "# Function to update the plot based on selected regions\n",
    "def update_plot(selected_regions):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    # Plot each selected region\n",
    "    for region in selected_regions:\n",
    "        plt.plot(timeseriesdf.index, timeseriesdf[region], label=region)\n",
    "\n",
    "    plt.title('COVID-19 Healthcare Admissions by Region')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Admissions')\n",
    "    plt.legend(title='NHS Regions')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Link the widget to the plot update function\n",
    "interactive_plot = interactive(update_plot, selected_regions=region_selector)\n",
    "\n",
    "display(interactive_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2e9a93-30d0-4770-b7f4-e11880236f73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
